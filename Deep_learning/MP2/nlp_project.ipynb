{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for NLP - Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RULES:\n",
    "\n",
    "* Do not create any additional cell\n",
    "\n",
    "* Fill in the blanks\n",
    "\n",
    "* All cells should be runnable (modulo trivial compatibility bugs that we'd fix)\n",
    "\n",
    "* 4 / 20 points will be allocated to the clarity of your code\n",
    "\n",
    "* Efficient code will have a bonus\n",
    "\n",
    "DELIVERABLE:\n",
    "\n",
    "* this notebook\n",
    "* the predictions of the SST test set\n",
    "\n",
    "DO NOT INCLUDE THE DATASETS IN THE DELIVERABLE.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = r\"C:\\Users\\dell\\Desktop\\MVA\\deeplearning\\MP2\\nlp_project\\data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Monolingual (English) word embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2vec():\n",
    "    def __init__(self, fname, nmax=100000):\n",
    "        self.load_wordvec(fname, nmax)\n",
    "        self.word2id = dict.fromkeys(self.word2vec.keys())\n",
    "        self.id2word = {v: k for k, v in self.word2id.items()}\n",
    "        self.embeddings = np.array(self.word2vec.values())\n",
    "    \n",
    "    def load_wordvec(self, fname, nmax):\n",
    "        self.word2vec = {}\n",
    "        with io.open(fname, encoding='utf-8') as f:\n",
    "            next(f) #skip the header\n",
    "            for i, line in enumerate(f):#enumerate over lines of the file + counter : i\n",
    "                word, vec = line.split(' ', 1)  # list of two elements the first is assigned to word and the second to vec\n",
    "                self.word2vec[word] = np.fromstring(vec, sep=' ')\n",
    "                if i == (nmax - 1):\n",
    "                    break\n",
    "        print('Loaded %s pretrained word vectors' % (len(self.word2vec)))\n",
    "\n",
    "    def most_similar(self, w, K=5):\n",
    "        # K most similar words: self.score  -  np.argsort \n",
    "        scores=[]\n",
    "        indexes_retained=[]\n",
    "        for key in self.word2vec:\n",
    "            if key==w:\n",
    "                scores.append(0)\n",
    "            else:\n",
    "                scores.append(self.score(w,key))\n",
    "        indexes_retained=np.argsort(scores)[-1*K:]     #find the index of the 5 biggest elements of scores\n",
    "        s=1\n",
    "        for i in indexes_retained[::-1]:\n",
    "            print('rank',s,[*self.word2vec][i])\n",
    "            s+=1\n",
    "            \n",
    "    def score(self, w1, w2):\n",
    "        # cosine similarity: np.dot  -  np.linalg.norm\n",
    "        return np.dot(self.word2vec[w1],self.word2vec[w2])/(np.linalg.norm(self.word2vec[w1])*np.linalg.norm(self.word2vec[w2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 150000 pretrained word vectors\n",
      "cat dog 0.671683666279249\n",
      "dog pet 0.6842064029669219\n",
      "dogs cats 0.7074389328052404\n",
      "paris france 0.7775108541288563\n",
      "germany berlin 0.7420295235998394\n",
      "rank 1 cats\n",
      "rank 2 kitty\n",
      "rank 3 kitten\n",
      "rank 4 feline\n",
      "rank 5 kitties\n",
      "None \n",
      "\n",
      "rank 1 dogs\n",
      "rank 2 puppy\n",
      "rank 3 Dog\n",
      "rank 4 doggie\n",
      "rank 5 canine\n",
      "None \n",
      "\n",
      "rank 1 dog\n",
      "rank 2 pooches\n",
      "rank 3 Dogs\n",
      "rank 4 doggies\n",
      "rank 5 canines\n",
      "None \n",
      "\n",
      "rank 1 france\n",
      "rank 2 Paris\n",
      "rank 3 parisian\n",
      "rank 4 london\n",
      "rank 5 berlin\n",
      "None \n",
      "\n",
      "rank 1 austria\n",
      "rank 2 europe\n",
      "rank 3 german\n",
      "rank 4 berlin\n",
      "rank 5 poland\n",
      "None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "w2v = Word2vec(os.path.join(PATH_TO_DATA, 'crawl-300d-200k.vec'), nmax=150000)\n",
    "\n",
    "# You will be evaluated on the output of the following:\n",
    "for w1, w2 in zip(('cat', 'dog', 'dogs', 'paris', 'germany'), ('dog', 'pet', 'cats', 'france', 'berlin')):\n",
    "    print(w1, w2, w2v.score(w1, w2))\n",
    "for w1 in ['cat', 'dog', 'dogs', 'paris', 'germany']:\n",
    "    print(w2v.most_similar(w1),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoV():\n",
    "    def __init__(self, w2v):\n",
    "        self.w2v = w2v\n",
    "    \n",
    "    \n",
    "        \n",
    "    def encode(self, sentences, idf=False):\n",
    "        # takes a list of sentences, outputs a numpy array of sentence embeddings\n",
    "        # see TP1 for help\n",
    "        sentemb = []\n",
    "        keys = list(self.w2v.word2vec.keys())\n",
    "        for sent in sentences:\n",
    "            if idf is False:\n",
    "                # mean of word vectors\n",
    "                \n",
    "                sentemb.append(np.mean([self.w2v.word2vec[w] for w in sent if w in keys],\n",
    "                                       axis=0))\n",
    "                #assert False, 'TODO: fill in the blank'\n",
    "            else:\n",
    "                # idf-weighted mean of word vectors\n",
    "                \n",
    "                vec = np.sum([idf1[w]*self.w2v.word2vec[w] for w in sent if w in keys],\n",
    "                             axis=0)/np.sum([idf1[w] for w in sent if w in keys])\n",
    "                sentemb.append(vec)\n",
    "                #assert False, 'TODO: fill in the blank'\n",
    "        return np.vstack(sentemb)\n",
    "   \n",
    "    \n",
    "    def most_similar(self, s,sentences,idf=False, K=5):\n",
    "        # get most similar sentences and **print** them\n",
    "        scores=[]\n",
    "        indexes_retained=[]\n",
    "        for sent in sentences:\n",
    "            if sent==s:\n",
    "                scores.append(0)\n",
    "            else:\n",
    "                scores.append(self.score(s,sent,idf))\n",
    "        indexes_retained=np.argsort(scores)[-1*K:]     #find the index of the 5 biggest elements of scores\n",
    "        s=1\n",
    "        for i in indexes_retained[::-1]:\n",
    "            print('rank',s,sentences[i])\n",
    "            s+=1\n",
    "\n",
    "    def score(self, s1, s2, idf=False):\n",
    "        # cosine similarity: use   np.dot  and  np.linalg.norm\n",
    "        enc1=self.encode([s1],idf)\n",
    "        enc2=self.encode([s2],idf)\n",
    "        return (np.dot(enc1,enc2.T)/(np.linalg.norm(enc1)*np.linalg.norm(enc2)))[0][0]\n",
    "    \n",
    "    def build_idf(self, sentences):\n",
    "        # build the idf dictionary: associate each word to its idf value\n",
    "        idf = {}\n",
    "        for sent in sentences:\n",
    "            for w in set(sent):\n",
    "                idf[w] = idf.get(w, 0) + 1\n",
    "        \n",
    "        for word in idf:\n",
    "            idf[word]= max(1,np.log10(len(sentences) / (idf[word])))\n",
    "        return idf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 150736 sentences\n",
      "0.5726258859719605\n",
      "0.012930870056152344\n"
     ]
    }
   ],
   "source": [
    "#w2v = Word2vec(os.path.join(PATH_TO_DATA, 'crawl-300d-1M.vec'), nmax=500000)\n",
    "s2v = BoV(w2v)\n",
    "\n",
    "# Load sentences in \"PATH_TO_DATA/sentences.txt\"\n",
    "sentences = []\n",
    "with open('data/sentences.txt') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        sent = line.rstrip().split() \n",
    "        #striping white spaces from the end of s<entences and splitting them to lists by whitespace\n",
    "        sentences.append(sent) #append list representing the sentence to the list sentences containing all sentences\n",
    "print('Found %s sentences' % len(sentences))\n",
    "\n",
    "# Build idf scores for each word\n",
    "idf1 =s2v.build_idf(sentences)\n",
    "\n",
    "# You will be evaluated on the output of the following:\n",
    "import time\n",
    "x=time.time()\n",
    "print(s2v.score('' if not sentences else sentences[7], '' if not sentences else sentences[13]))\n",
    "y=(time.time()-x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1949.1476287841797"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y*len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank 1 ['an', 'african', 'american', 'man', 'smiling', '.']\n",
      "rank 2 ['a', 'little', 'african', 'american', 'boy', 'and', 'girl', 'looking', 'up', '.']\n",
      "rank 3 ['an', 'afican', 'american', 'woman', 'standing', 'behind', 'two', 'small', 'african', 'american', 'children', '.']\n",
      "rank 4 ['an', 'african', 'american', 'man', 'is', 'sitting', '.']\n",
      "rank 5 ['a', 'girl', 'in', 'black', 'hat', 'holding', 'an', 'african', 'american', 'baby', '.']\n"
     ]
    }
   ],
   "source": [
    "s2v.most_similar('' if not sentences else sentences[10], sentences)  # BoV-mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47514508753687823"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2v.score('' if not sentences else sentences[7], '' if not sentences else sentences[13], idf=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank 1 ['an', 'african', 'american', 'man', 'smiling', '.']\n",
      "rank 2 ['an', 'african', 'american', 'man', 'is', 'sitting', '.']\n",
      "rank 3 ['a', 'little', 'african', 'american', 'boy', 'and', 'girl', 'looking', 'up', '.']\n",
      "rank 4 ['an', 'afican', 'american', 'woman', 'standing', 'behind', 'two', 'small', 'african', 'american', 'children', '.']\n",
      "rank 5 ['a', 'girl', 'in', 'black', 'hat', 'holding', 'an', 'african', 'american', 'baby', '.']\n"
     ]
    }
   ],
   "source": [
    "s2v.most_similar('' if not sentences else sentences[10], sentences, idf=True)  # BoV-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Multilingual (English-French) word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider a bilingual dictionary of size V_a (e.g French-English).\n",
    "\n",
    "Let's define **X** and **Y** the **French** and **English** matrices.\n",
    "\n",
    "They contain the embeddings associated to the words in the bilingual dictionary.\n",
    "\n",
    "We want to find a **mapping W** that will project the source word space (e.g French) to the target word space (e.g English).\n",
    "\n",
    "Procrustes : **W\\* = argmin || W.X - Y ||  s.t  W^T.W = Id**\n",
    "has a closed form solution:\n",
    "**W = U.V^T  where  U.Sig.V^T = SVD(Y.X^T)**\n",
    "\n",
    "In what follows, you are asked to: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50000 english pretrained word vectors\n",
      "Loaded 50000 french pretrained word vectors\n"
     ]
    }
   ],
   "source": [
    "# 1 - Download and load 50k first vectors of\n",
    "#     https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.en.vec\n",
    "#     https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.fr.vec\n",
    "\n",
    "# TYPE CODE HERE\n",
    "nmax = 50000\n",
    "word2vec_eng = {}\n",
    "with io.open('./data/wiki.en.vec', encoding='utf-8') as f:\n",
    "    next(f)\n",
    "    for i, line in enumerate(f):\n",
    "        word, vec = line.split(' ', 1)\n",
    "        word2vec_eng[word] = np.fromstring(vec, sep=' ')\n",
    "        if i == (nmax - 1):\n",
    "            break\n",
    "    print('Loaded %s english pretrained word vectors' % (len(word2vec_eng)))\n",
    "    \n",
    "word2vec_fr = {}\n",
    "with io.open('./data/wiki.fr.vec', encoding='utf-8') as f:\n",
    "    next(f)\n",
    "    for i, line in enumerate(f):\n",
    "        word, vec = line.split(' ', 1)\n",
    "        word2vec_fr[word] = np.fromstring(vec, sep=' ')\n",
    "        if i == (nmax - 1):\n",
    "            break     \n",
    "    print('Loaded %s french pretrained word vectors' % (len(word2vec_fr)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Get words that appear in both vocabs (= identical character strings)\n",
    "#     Use it to create the matrix X and Y (of aligned embeddings for these words)\n",
    "\n",
    "# TYPE CODE HERE\n",
    "identical_words = []\n",
    "keys_eng = set(word2vec_eng.keys())\n",
    "keys_fr = set(word2vec_fr.keys())\n",
    "for word in word2vec_eng:\n",
    "    if word in word2vec_fr:\n",
    "        identical_words.append(word)\n",
    "X = []\n",
    "Y = []\n",
    "for word in identical_words:\n",
    "    X.append(word2vec_eng[word])\n",
    "    Y.append(word2vec_fr[word])\n",
    "X,Y = np.array(X),np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - Solve the Procrustes using the scipy package and: scipy.linalg.svd() and get the optimal W\n",
    "#     Now W*French_vector is in the same space as English_vector\n",
    "\n",
    "# TYPE CODE HERE\n",
    "R = np.dot(Y,X.T)\n",
    "U, S, V = np.linalg.svd(R) \n",
    "W = np.dot(U,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the nearest english words to the french word place are ['place', 'position', 'places', 'part', 'mis']\n",
      "the nearest english words to the french word automobile are ['automobile', 'automobiles', 'moto', 'automotive', 'bugatti']\n",
      "the nearest english words to the french word population are ['population', 'populations', 'hab', '/km²', 'km²']\n",
      "the nearest english words to the french word article are ['article', 'articles', 'admissible', 'interwiki', 'page']\n"
     ]
    }
   ],
   "source": [
    "# 4 - After alignment with W, give examples of English nearest neighbors of some French words (and vice versa)\n",
    "#     You will be evaluated on that part and the code above\n",
    "\n",
    "# TYPE CODE HERE\n",
    "M = np.dot(W,X)\n",
    "\n",
    "def nearest_neighbors_eng(M,Y,french_word,identical_words,K=5):\n",
    "    scores=[]\n",
    "    i= identical_words.index(french_word)\n",
    "    vec = M[i]\n",
    "    for x in list(Y):\n",
    "        scores.append(np.dot(x,vec)/(np.linalg.norm(x)*np.linalg.norm(vec)))\n",
    "    indexes_retained=np.argsort(scores)[-1*K:]  \n",
    "    return [identical_words[i] for i in indexes_retained[::-1]]\n",
    "\n",
    "print('the nearest english words to the french word place are',nearest_neighbors_eng(M,Y,'place',identical_words))\n",
    "print('the nearest english words to the french word automobile are',nearest_neighbors_eng(M,Y,'automobile',identical_words))\n",
    "print('the nearest english words to the french word population are',nearest_neighbors_eng(M,Y,'population',identical_words))\n",
    "print('the nearest english words to the french word article are',nearest_neighbors_eng(M,Y,'article',identical_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the nearest french words to the english word place are ['place', 'position', 'places', 'billboard', 'chart']\n",
      "the nearest french words to the english word car are ['car', 'mais', 'pas', 'si', 'ne']\n",
      "the nearest french words to the english word population are ['population', 'populations', '/km²', 'km²', 'proportion']\n",
      "the nearest french words to the english word article are ['article', 'articles', 'pertinent', 'admissible', 'page']\n",
      "the nearest french words to the english word food are ['food', 'foods', 'nutrition', 'health', 'drug']\n"
     ]
    }
   ],
   "source": [
    "def nearest_neighbors_fr(M,Y,eng_word,identical_words,K=5):\n",
    "    scores=[]\n",
    "    i= identical_words.index(eng_word)\n",
    "    vec = Y[i]\n",
    "    for x in list(M):\n",
    "        scores.append(np.dot(x,vec)/(np.linalg.norm(x)*np.linalg.norm(vec)))\n",
    "    indexes_retained=np.argsort(scores)[-1*K:]  \n",
    "    return [identical_words[i] for i in indexes_retained[::-1]]\n",
    "\n",
    "print('the nearest french words to the english word place are',nearest_neighbors_fr(M,Y,'place',identical_words))\n",
    "print('the nearest french words to the english word car are',nearest_neighbors_fr(M,Y,'car',identical_words))\n",
    "print('the nearest french words to the english word population are',nearest_neighbors_fr(M,Y,'population',identical_words))\n",
    "print('the nearest french words to the english word article are',nearest_neighbors_fr(M,Y,'article',identical_words))\n",
    "print('the nearest french words to the english word food are',nearest_neighbors_fr(M,Y,'food',identical_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to dive deeper on this subject: https://github.com/facebookresearch/MUSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Sentence classification with BoV and scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Load train/dev/test of Stanford Sentiment TreeBank (SST)\n",
    "#     (https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf)\n",
    "\n",
    "# TYPE CODE HERE\n",
    "train_sentences = []\n",
    "train_labels = []\n",
    "path = './data/SST/stsa.fine.train'\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        label, sent = line.split(' ', 1)\n",
    "        train_sentences.append(sent.rstrip().split())\n",
    "        train_labels.append(int(label))\n",
    "    \n",
    "dev_sentences = []\n",
    "dev_labels = []\n",
    "path = './data/SST/stsa.fine.dev'\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        label, sent = line.split(' ', 1)\n",
    "        dev_sentences.append(sent.rstrip().split())\n",
    "        dev_labels.append(int(label))\n",
    "        \n",
    "test_sentences = []\n",
    "path = './data/SST/stsa.fine.test.X'\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        test_sentences.append(line.rstrip().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 150000 pretrained word vectors\n"
     ]
    }
   ],
   "source": [
    "# 2 - Encode sentences with the BoV model above\n",
    "w2v = Word2vec(os.path.join(PATH_TO_DATA, 'crawl-300d-200k.vec'), nmax=150000)\n",
    "s2v = BoV(w2v)\n",
    "# TYPE CODE HERE\n",
    " # BoV-mean\n",
    "train_bov_mean = s2v.encode(train_sentences)\n",
    "dev_bov_mean = s2v.encode(dev_sentences)\n",
    "test_bov_mean = s2v.encode(test_sentences)\n",
    " # BoV-idf\n",
    "idf1 = s2v.build_idf(train_sentences+dev_sentences+test_sentences)\n",
    "train_bov_idf = s2v.encode(train_sentences,idf=True)\n",
    "dev_bov_idf = s2v.encode(dev_sentences,idf=True)\n",
    "test_bov_idf = s2v.encode(test_sentences,idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score on dev set when using mean BoV is :  42.87 % and is given by given by a regularization parameter C =  3\n",
      "The training score using the average of word vectors is:  48.53 %\n",
      "The best score on dev set when using weighted average is :  43.23 % and is given by given by a regularization parameter C =  1\n",
      "The training score using the weighted-average is:  47.6 %\n"
     ]
    }
   ],
   "source": [
    "# 3 - Learn Logistic Regression on top of sentence embeddings using scikit-learn\n",
    "#     (consider tuning the L2 regularization on the dev set)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "C = [0.001,0.01,0.05,0.1,0.5,1,3,10,20,30,40,50,60,70,80,90,100] # regularization strengths\n",
    "scores = []\n",
    "for c in C:\n",
    "    logReg = LogisticRegression(penalty='l2',C = c)\n",
    "    logReg.fit(train_bov_mean,train_labels)\n",
    "    score = logReg.score(dev_bov_mean,dev_labels)\n",
    "    scores.append(score)\n",
    "    \n",
    "index_best_score=np.argmax(scores)\n",
    "print('The best score on dev set when using mean BoV is : ',round(scores[index_best_score]*100,2),'% \\\n",
    "and is given by given by a regularization parameter C = ',C[index_best_score])\n",
    "\n",
    "logReg = LogisticRegression(penalty='l2',C = C[index_best_score])\n",
    "logReg.fit(train_bov_mean,train_labels)\n",
    "score = logReg.score(train_bov_mean,train_labels)\n",
    "print('The training score using the average of word vectors is: ',round(score*100,2),'%')\n",
    "\n",
    "C = [0.001,0.01,0.05,0.1,0.5,1,3,10,20,30,40,50,60,70,80,90,100] # regularization strengths\n",
    "scores = []\n",
    "for c in C:\n",
    "    logReg = LogisticRegression(penalty='l2',C = c)\n",
    "    logReg.fit(train_bov_idf,train_labels)\n",
    "    score = logReg.score(dev_bov_idf,dev_labels)\n",
    "    scores.append(score)\n",
    "    \n",
    "index_best_score=np.argmax(scores)\n",
    "print('The best score on dev set when using weighted average is : ',round(scores[index_best_score]*100,2),'% \\\n",
    "and is given by given by a regularization parameter C = ',C[index_best_score])\n",
    "\n",
    "logReg = LogisticRegression(penalty='l2',C = C[index_best_score])\n",
    "logReg.fit(train_bov_idf,train_labels)\n",
    "score = logReg.score(train_bov_idf,train_labels)\n",
    "print('The training score using the weighted-average is: ',round(score*100,2),'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 - Produce 2210 predictions for the test set (in the same order). One line = one prediction (=0,1,2,3,4).\n",
    "#     Attach the output file \"logreg_bov_y_test_sst.txt\" to your deliverable.\n",
    "#     You will be evaluated on the results of the test set.\n",
    "\n",
    "# TYPE CODE HERE\n",
    "path = './logreg_bov_y_test_sst.txt'\n",
    "output_file = open(path, 'w')\n",
    "logReg = LogisticRegression(penalty='l2',C = 3)\n",
    "logReg.fit(train_bov_mean,train_labels)\n",
    "predictions = logReg.predict(test_bov_mean)\n",
    "for i in range(len(predictions)):\n",
    "    output_file.write(\"%s\\n\" % predictions[i])\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3669241573033708\n",
      "0.35603996366939145\n"
     ]
    }
   ],
   "source": [
    "# BONUS!\n",
    "# 5 - Try to improve performance with another classifier\n",
    "#     Attach the output file \"XXX_bov_y_test_sst.txt\" to your deliverable (where XXX = the name of the classifier)\n",
    "from numpy.core.umath_tests import inner1d\n",
    "# TYPE CODE HERE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "path = './RFC_bov_y_test_sst.txt'\n",
    "output_file = open(path, 'w')\n",
    "rfc=RandomForestClassifier(max_depth=3, n_estimators=10)\n",
    "rfc.fit(train_bov_mean,train_labels)\n",
    "predictions = rfc.predict(test_bov_mean)\n",
    "for i in range(len(predictions)):\n",
    "    output_file.write(\"%s\\n\" % predictions[i])\n",
    "output_file.close()\n",
    "print(rfc.score(train_bov_idf,train_labels))\n",
    "print(rfc.score(dev_bov_mean,dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4359673024523161"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "path = './SVC_bov_y_test_sst.txt'\n",
    "output_file = open(path, 'w')\n",
    "clf = SVC(C=200)\n",
    "clf.fit(train_bov_mean,train_labels)\n",
    "clf.score(dev_bov_mean,dev_labels)\n",
    "predictions = clf.predict(test_bov_mean)\n",
    "for i in range(len(predictions)):\n",
    "    output_file.write(\"%s\\n\" % predictions[i])\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Sentence classification with LSTMs in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 - Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Activation,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Load train/dev/test sets of SST\n",
    "\n",
    "\n",
    "# TYPE CODE HERE\n",
    "def load_data_sent(filename, test=False):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    with io.open(filename, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if not test:\n",
    "                label, line = line.split(' ', 1)\n",
    "                labels.append(label)\n",
    "            sentences.append(line.rstrip())\n",
    "    \n",
    "    return sentences, labels\n",
    "PATH='data/SST/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_test, _ = load_data_sent(os.path.join(PATH, 'stsa.fine.test.X'), True)\n",
    "sst_dev, sst_dev_label = load_data_sent(os.path.join(PATH, 'stsa.fine.dev'))\n",
    "sst_train, sst_train_label = load_data_sent(os.path.join(PATH, 'stsa.fine.train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Transform text to integers using keras.preprocessing.text.one_hot function\n",
    "#     https://keras.io/preprocessing/text/\n",
    "\n",
    "# TYPE CODE HERE\n",
    "from keras.preprocessing.text import text_to_word_sequence, one_hot\n",
    "\n",
    "def get_vocsize(*args):\n",
    "    r = []    \n",
    "    for a in args:\n",
    "        for e in a:\n",
    "            words = text_to_word_sequence(e) #spliting sent to words\n",
    "            for w in words:\n",
    "                r.append(w)            \n",
    "    return len(list(set(r)))\n",
    "#one hot encoding all sentences\n",
    "def text_to_num(n, *args):\n",
    "    r = []    \n",
    "    for a in args:\n",
    "        data = []\n",
    "        for e in a:\n",
    "            data.append(one_hot(e, n))        \n",
    "        r.append(data)    \n",
    "    return np.array(r[0]), np.array(r[1]), np.array(r[2])\n",
    "\n",
    "n = get_vocsize(sst_test, sst_dev, sst_train)\n",
    "X_train, X_dev, X_test = text_to_num(n, sst_train, sst_dev, sst_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Padding input data**\n",
    "\n",
    "Models in Keras (and elsewhere) take batches of sentences of the same length as input. It is because Deep Learning framework have been designed to handle well Tensors, which are particularly suited for fast computation on the GPU.\n",
    "\n",
    "Since sentences have different sizes, we \"pad\" them. That is, we add dummy \"padding\" tokens so that they all have the same length.\n",
    "\n",
    "The input to a Keras model thus has this size : (batchsize, maxseqlen) where maxseqlen is the maximum length of a sentence in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - Pad your sequences using keras.preprocessing.sequence.pad_sequences\n",
    "#     https://keras.io/preprocessing/sequence/\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train = pad_sequences(X_train)\n",
    "X_dev = pad_sequences(X_dev)\n",
    "X_test = pad_sequences(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 - Design and train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 - Design your encoder + classifier using keras.layers\n",
    "#     In Keras, Torch and other deep learning framework, we create a \"container\" which is the Sequential() module.\n",
    "#     Then we add components to this contained : the lookuptable, the LSTM, the classifier etc.\n",
    "#     All of these components are contained in the Sequential() and are trained together.\n",
    "\n",
    "\n",
    "# ADAPT CODE BELOW\n",
    "\n",
    "\n",
    "\n",
    "embed_dim  = 64  # word embedding dimension\n",
    "nhid       = 32  # number of hidden units in the LSTM\n",
    "vocab_size = n  # size of the vocabulary\n",
    "n_classes  = 5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embed_dim))\n",
    "model.add(LSTM(nhid, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(n_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, None, 64)          1141696   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 1,154,277\n",
      "Trainable params: 1,154,277\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, None, 64)          1141696   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 1,154,277\n",
      "Trainable params: 1,154,277\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 5 - Define your loss/optimizer/metrics\n",
    "\n",
    "# MODIFY CODE BELOW\n",
    "\n",
    "loss_classif     =  'categorical_crossentropy' # find the right loss for multi-class classification\n",
    "optimizer        =  'adam' # find the right optimizer\n",
    "metrics_classif  =  ['accuracy']\n",
    "\n",
    "# Observe how easy (but blackboxed) this is in Keras\n",
    "model.compile(loss=loss_classif,\n",
    "              optimizer=optimizer,\n",
    "              metrics=metrics_classif)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 6 - Train your model and find the best hyperparameters for your dev set\n",
    "#     you will be evaluated on the quality of your predictions on the test set\n",
    "\n",
    "# ADAPT CODE BELOW\n",
    "bs = 64\n",
    "\n",
    "n_epochs = 20\n",
    "y_train = np_utils.to_categorical(train_labels)\n",
    "y_dev = np_utils.to_categorical(dev_labels)\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=bs,epochs=n_epochs,validation_data=(X_dev, y_dev),verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'dev'], loc='upper left')\n",
    "plt.savefig('train_dev_evol.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 - Generate your predictions on the test set using model.predict(x_test)\n",
    "#     https://keras.io/models/model/\n",
    "#     Log your predictions in a file (one line = one integer: 0,1,2,3,4)\n",
    "#     Attach the output file \"logreg_lstm_y_test_sst.txt\" to your deliverable.\n",
    "\n",
    "# TYPE CODE HERE\n",
    "path = './logreg_lstm_y_test_sst.txt'\n",
    "thefile = open(path, 'w')\n",
    "predictions = model.predict_classes(X_test)\n",
    "for i in range(len(predictions)):\n",
    "    thefile.write(\"%s\\n\" % predictions[i])\n",
    "thefile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 -- innovate !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 - Open question: find a model that is better on your dev set\n",
    "#     (e.g: use a 1D ConvNet, use a better classifier, pretrain your lookup tables ..)\n",
    "#     you will get point if the results on the test set are better: be careful of not overfitting your dev set too much..\n",
    "#     Attach the output file \"XXX_XXX_y_test_sst.txt\" to your deliverable.\n",
    "\n",
    "def get_voc(*args):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            *args (lists of strings): list of the strings of the training/dev/testing dataset\n",
    "        Returns:\n",
    "            list: a list containing all the words (unique)\n",
    "    \"\"\"\n",
    "    r = []\n",
    "    \n",
    "    for a in args:\n",
    "        for e in a:\n",
    "            words = text_to_word_sequence(e)\n",
    "            for w in words:\n",
    "                r.append(w)\n",
    "                \n",
    "    uniq_word = list(set(r)) # set use to discard duplicates\n",
    "    \n",
    "    return {w: None for w in uniq_word}\n",
    "\n",
    "def word_to_embeddings(filename, *args):\n",
    "    voca = get_voc(*args)\n",
    "    w2e = {}\n",
    "    \n",
    "    max_size = len(voca)\n",
    "    counter = 0\n",
    "    with io.open(filename, encoding='utf-8') as f:\n",
    "        next(f) # to skip the header\n",
    "        for line in f:\n",
    "            if counter == max_size:\n",
    "                break\n",
    "            word, vec = line.split(' ', 1)\n",
    "            if word.strip().lower() in voca:\n",
    "                w2e[word] = np.fromstring(vec, sep=' ')\n",
    "                counter += 1\n",
    "    \n",
    "    return w2e\n",
    "\n",
    "# take 20 seconds on my computer...\n",
    "w2v_dict = word_to_embeddings(os.path.join(PATH_TO_DATA, 'wiki.en.vec'), sst_test, sst_dev, sst_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulaire = set(get_voc(sst_test, sst_dev, sst_train)) # voc from the SST files\n",
    "voca_w2v = set(w2v_dict.keys()) # voc using word_2_vec from wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmbeddings(voc_list):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            voc_list (list): list of unique words extracted from all questions\n",
    "        Returns:\n",
    "            embeddings (ndarray): A matrix of shape (vocabulary size, embeddings_size)\n",
    "    \"\"\"\n",
    "    embeddings = np.zeros((len(voc_list), 300))\n",
    "    for i, w in enumerate(voc_list):\n",
    "        if w in w2v_dict.keys():\n",
    "            embeddings[i] = w2v_dict[w]\n",
    "        else: embeddings[i]=300*[0]\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(get_voc(sst_test, sst_dev, sst_train))\n",
    "embedding_matrix = getEmbeddings(vocab)\n",
    "\n",
    "# need to transform X_test, X_train, X_dev into matrix of idx of word in embedding_matrix\n",
    "def preprocess_matrix(X, vocab, max_len):\n",
    "    vocab = {k: i for i, k in enumerate(vocab)}\n",
    "    new_X = np.zeros((len(X), max_len), dtype=int)\n",
    "    \n",
    "    for i, e in enumerate(X):\n",
    "        w_list = text_to_word_sequence(e)\n",
    "        size = len(w_list)\n",
    "        for j, w in enumerate(w_list):\n",
    "            new_X[i,max_len-size+j] = vocab[w]\n",
    "            \n",
    "    return new_X\n",
    "\n",
    "# sst_test, sst_dev, sst_train\n",
    "new_X_test = preprocess_matrix(sst_test, vocab, max_len=52)\n",
    "new_X_train = preprocess_matrix(sst_train, vocab, max_len=52)\n",
    "new_X_dev = preprocess_matrix(sst_dev, vocab, max_len=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 52)                0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, 52, 300)           5351700   \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 5,445,465\n",
      "Trainable params: 93,765\n",
      "Non-trainable params: 5,351,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "voc_size = embedding_matrix.shape[0]\n",
    "word2vec_dim = embedding_matrix.shape[1]\n",
    "max_len = 52 #maximum number of word in a string \n",
    "activation = 'tanh'\n",
    "q_hidden_units = 64\n",
    "merge_hidden_units = 50\n",
    "\n",
    "\n",
    "_input = Input(shape=[max_len], dtype='int32')\n",
    "\n",
    "# get the embedding layer\n",
    "embedded = Embedding(\n",
    "        input_dim=voc_size,\n",
    "        output_dim=word2vec_dim,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=max_len,\n",
    "        trainable=False,\n",
    "        mask_zero=False\n",
    "    )(_input)\n",
    "\n",
    "lstm = LSTM(q_hidden_units, return_sequences=False)(embedded)\n",
    "probabilities = Dense(5, activation='softmax')(lstm)\n",
    "model2 = Model(input=[_input], output=probabilities)\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam',  metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history=model2.fit(new_X_train, y_train, batch_size=bs,validation_data=(new_X_dev, y_dev),epochs=20,verbose=0)\n",
    "\n",
    "print(history.history.keys())\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'dev'], loc='upper left')\n",
    "plt.savefig('train_dev_evol_2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Generate your predictions on the test set using model.predict(x_test)\n",
    "\n",
    "\n",
    "# TYPE CODE HERE\n",
    "path = './pretrained-embeddings_lstm_y_test_sst.txt'\n",
    "thefile = open(path, 'w')\n",
    "predictions = better_model.predict(X_test)\n",
    "for i in range(len(predictions)):\n",
    "    thefile.write(\"%s\\n\" % np.argmax(predictions[i]))\n",
    "thefile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
